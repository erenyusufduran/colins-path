# What is Apache Kafka?

Today, billions of data sources continuously generate streams of data records, including streams of events. An event is a digital record of an action that happened and the time that it happened. Typically, an event is an action that drives another action as part of a process. A customer placing an order, choosing a seat on a flight, or submitting a registration form are all examples of events.

These streams offer opportunities for applications that respond to data or events in real-time. A streaming platform enables developers to build applications that continuously consume and process these streams at extremely high speeds, with a high level of fidelity and accuracy based on the correct order of their occurrence.

LinkedIn developed Kafka in 2011 as a high-throughput message broker for its own use, then open-sourced and donated Kafka to the <a href="https://kafka.apache.org/">Apache Software Foundation</a>. Today, Kafka has evolved into the most widely-used streaming platform, capable of ingesting and processing trillions of records per day without any perceptible performance lag as volumes scale. Fortune 500 organizations such as Target, Microsoft, AirBnB, and Netflix rely on Kafka to deliver real-time, data-driven experiences to their customers.

---

## How Kafka Works

**Kafka has three primary capabilities:**

1. It enables applications to publics or subscribe to data or event streams.
2. It stores records accurately in a fault-tolerant and durable way.
3. It processes records in real-time.

### **Developers can leverage these Kafka capabilities through four APIs:**

- **Producer API:** This enables an application to publish a stream to a Kafka topic. A topic is a named log that stores the recors in the order they occured relative to one another. After a record is written to a topic, it can't be altered or deleted; instead, it remains in the topic for a preconfigured amount of time or until storage space runs out.
- **Consumer API:** This enables an application to subscribe to one or more topics and to ingest and process the stream stored in the topic. It can work with records in the topic in real-time, or it can ingest and process past records.
- **Streams API:** This builds on the _Producer and Consumer APIs_ and adds complex processing capabilities that enable an application to perform continuous, front-to-back stream processing, to consume records from one or more topics, to analyze or aggregate or transform them as required, and to publish resulting streams to the same topics or other topics. While the Producer and Consumer APIs can be used for simple stream processing, it's the Streams API that enables development of more sophisticated data and event-streaming applications.
- **Connector API:** This lets developers build connectors, which are reusable producers or consumers that simplify and automate the integration of a data source into a Kafka cluster.

---

## Kafka Use Cases

Kafka is used primarily for creating two kinds of applications:

- _Real-time streaming data pipelins:_
  - Applications designed spesifically to move millions and millions of data or event records between enterprise systems and move them reliably, without risk of corruption, duplication of data, and other problems that typically occur when moving such huge volumes of data at high speeds.
- _Real-time streaming applications:_
  - Applications that are driven by record or event streams and that generate streams of their own. If you spend any time online, you encounter scores of these applications every day, from the retail site that continually updates the quantity of a product at your local store, to sites that display personalized recommendations or advertising based on clickstream analysis.

---

## Kafka vs. RabbitMQ

RabbitMQ is a very popular open source <a href="https://www.ibm.com/topics/message-brokers">message broker</a>, a type of middleware that enables applications, systems, and services to communicate with each other by translating messageing protocols between them.

Because Kafka began as a kind of message broker and because RabbitMQ supports a publish/subscribe messaging model, Kafka and RabbitMQ are often compared as alternatives. But, the comparisons aren't really practical, and they often dive into technical details that are beside the point when choosing between the two. For example, that Kafka topics can have multiple subscribers, whereas each RabbitMQ message can have only one; or that Kafka topics are durable, whereas RabbitMQ messages are deleted once consumed.

**The Bottom Line is:**

- Kafka is a stream processing platform that enables applications to publish, consume, and process high volumes of record streams in a fast and durable way;
- RabbitMQ is a message broker that enables applications that use different messaging protocols to send messages to, and receive messages from, one another.
